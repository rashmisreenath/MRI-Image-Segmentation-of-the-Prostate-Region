{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a3e3218",
   "metadata": {},
   "source": [
    "### Basic operation done on image before using models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e31885f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob            # to find similar paths\n",
    "import nibabel as nib  # to handle .nii files\n",
    "import nrrd            # read and write nrrd files into and from numpy arrays\n",
    "'Nrrd (\"nearly raw raster data\") is a library and file format for the representation and processing of n-dimensional raster data.'\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_imgs_labels_paths(PATH):\n",
    "    \n",
    "    dataset_path = {}\n",
    "    imgs_path =[]\n",
    "    labls_path = []\n",
    "    number_images = []\n",
    "\n",
    "    for patient in os.listdir(PATH):\n",
    "        # to check if the patient  folder name ends with a digit\n",
    "        if patient.split('/')[-1].isdigit():\n",
    "            \n",
    "            for technic in  os.listdir(os.path.join(PATH, patient)):\n",
    "                if technic in ['ADC','DWI', 'T2W']:\n",
    "                    images_path = sorted(glob.glob(os.path.join(PATH, patient, technic)+'/*.nii'))\n",
    "                    imgs_path.append(images_path)\n",
    "                    number_images.append(len(images_path))\n",
    "\n",
    "\n",
    "                elif technic in ['label']:\n",
    "                    labels_path = sorted(glob.glob(os.path.join(PATH, patient, technic)+'/*.nrrd'))\n",
    "                    labls_path.append(labels_path)\n",
    "                    \n",
    "                else:\n",
    "                    print('there is another folder named: ', PATH, patient, technic)\n",
    "\n",
    "            number_images.append(len(labels_path))\n",
    "\n",
    "            dataset_path[os.path.join(PATH, patient)] = [imgs_path, labels_path, number_images]\n",
    "            imgs_path =[]\n",
    "            labls_path =[]\n",
    "            number_images = []\n",
    "    return dataset_path\n",
    "\n",
    "\n",
    "def read_label(img_path, resize_shape , num_classes):\n",
    "    readdata, header = nrrd.read(img_path)\n",
    "    label = cv2.resize( readdata, resize_shape)\n",
    "    label = label.astype(np.uint8)\n",
    "    label = tf.one_hot(tf.squeeze(label), depth= num_classes)\n",
    "    label = label.numpy().astype(np.uint8)\n",
    "    return label\n",
    "\n",
    "\n",
    "\n",
    "def read_image(path, resize_shape):\n",
    "        \n",
    "    image = nib.load(path) \n",
    "    image = np.array(image.dataobj)\n",
    "    image = image.astype(float)\n",
    "    image = cv2.resize( image, resize_shape )\n",
    "    image = cv2.normalize(image, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    #print(path, 'image shape', image.shape)\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "def read_imgs_labels(dataset_paths, resize_shape, num_classes):\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for k , i in dataset_paths.items():\n",
    "       \n",
    "        image_paths = i[0]\n",
    "        label_path = i[1]\n",
    "        number_paths = i[2]\n",
    "        assert all([1 == num for num in number_paths])\n",
    "        \n",
    "        for a, d, t, l in zip(image_paths[0], image_paths[1], image_paths[2],label_path  ):\n",
    "            img_adc = read_image(a, resize_shape)\n",
    "            img_dwi = read_image(d, resize_shape)\n",
    "            img_t2w = read_image(t, resize_shape)\n",
    "            label_img = read_label(l, resize_shape , num_classes)\n",
    "            assert img_adc.shape == img_dwi.shape == img_t2w.shape == label_img.shape[:3]\n",
    "\n",
    "            for ch in range(img_adc.shape[2]):\n",
    "                x_train.append(np.stack([img_adc[:,:,ch],img_dwi[:,:,ch],img_t2w[:,:,ch]], axis=2))\n",
    "                y_train.append(label_img[:,:,ch,:])\n",
    "        #print('--------------------------------------------------------------')\n",
    "    x_train = np.stack((x_train))\n",
    "    y_train = np.stack((y_train))\n",
    "    return x_train, y_train\n",
    "\n",
    "\n",
    "@tf.function()\n",
    "def preparation(image, label , center_crop_rate=0.7, input_shape=(256, 256) ):\n",
    "    \n",
    "  \n",
    "    image =  tf.image.central_crop(image, center_crop_rate)\n",
    "    label =  tf.image.central_crop(label, center_crop_rate)\n",
    "\n",
    "    image =  tf.image.resize(image, input_shape, method='bilinear')\n",
    "    label =  tf.image.resize(label, input_shape, method='bilinear')\n",
    "  \n",
    "    image = tf.cast(image, dtype= tf.float32)\n",
    "    label = tf.cast(label, dtype= tf.float32 )  \n",
    "    \n",
    "    return image, label\n",
    "\n",
    "@tf.function()\n",
    "def normalize(image, label):\n",
    "    # normalizing the images to [-1, 1]\n",
    "   \n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    #image = (image / 127.5) - 1\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "@tf.function()\n",
    "def random_augmentation(image, label):\n",
    "    \n",
    "        \n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.rot90(image, k=1, name=None)\n",
    "        label = tf.image.rot90(label, k=1, name=None)\n",
    "        \n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.rot90(image, k=3, name=None)\n",
    "        label = tf.image.rot90(label, k=3, name=None)\n",
    "        \n",
    "    \n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        # random mirroring\n",
    "        image = tf.image.flip_left_right(image)\n",
    "        label = tf.image.flip_left_right(label)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "@tf.function()\n",
    "def load_image_train(image_file, label_file, input_shape):\n",
    "    image, label= preparation(image_file, label_file, center_crop_rate=0.7, input_shape=input_shape)\n",
    "    image, label = random_augmentation(image, label)\n",
    "    image, label = normalize(image, label)\n",
    "    return image, label\n",
    "\n",
    "@tf.function()\n",
    "def load_image_test(image_file, label_file, input_shape):\n",
    "    image, label= preparation(image_file, label_file, center_crop_rate=0.7, input_shape=input_shape)\n",
    "    #image, label = random_augmentation(image, label)\n",
    "    image, label = normalize(image, label)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def create_train_test_dataset(x_train, y_train, number_test_image, buffer_size, batch_size, input_shape):\n",
    "    \n",
    "    x_test, y_test = x_train[:number_test_image,:,:,], y_train[:number_test_image,:,:,]\n",
    "    x_train, y_train = x_train[number_test_image:,:,:,], y_train[number_test_image:,:,:,]\n",
    "    \n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_dataset = train_dataset.map(lambda x, y: load_image_train(x, y, input_shape) , num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_dataset = train_dataset.shuffle(buffer_size)\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    \n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    test_dataset = test_dataset.map(lambda x, y: load_image_test(x, y, input_shape) , num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def show_img(img,label, n_classes):\n",
    "    img = img[0,:,:,:]\n",
    "    label = label[0,:,:,:]\n",
    "\n",
    "    plt.imshow(img)\n",
    "    fig, axs = plt.subplots(1,n_classes, figsize=(15, 6), facecolor='w', edgecolor='k')\n",
    "    axs = axs.ravel()\n",
    "    for i in range(n_classes):\n",
    "        axs[i].imshow(label[:,:,i])\n",
    "        axs[i].set_title('Ground T of Channel ' + str(i))\n",
    "        print('Unique numbers in channel {} are {},{}'.format(i, np.min(np.unique(label[:, :, i])),\n",
    "                                                              np.max(np.unique(label[:, :, i]))))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f3bfe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
